{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hardware_Model</th>\n",
       "      <th>SDK_Version</th>\n",
       "      <th>Manufacture</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UUID  Language  Hardware_Model  SDK_Version  Manufacture  Screen_Size  \\\n",
       "0    48         0              40            3           18           23   \n",
       "1    48         0              40            3           18           23   \n",
       "2    48         0              40            3           18           23   \n",
       "3    48         0              40            3           18           23   \n",
       "4    48         0              40            3           18           23   \n",
       "\n",
       "   Time_Zone  Country_Code  \n",
       "0          7             1  \n",
       "1          7             1  \n",
       "2          7             1  \n",
       "3          7             1  \n",
       "4          7             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_of_CPU_Cores</th>\n",
       "      <th>pLN1</th>\n",
       "      <th>p.2</th>\n",
       "      <th>pLN3</th>\n",
       "      <th>pt4</th>\n",
       "      <th>pi5</th>\n",
       "      <th>pe6</th>\n",
       "      <th>pLN7</th>\n",
       "      <th>p58</th>\n",
       "      <th>pLN9</th>\n",
       "      <th>...</th>\n",
       "      <th>avdu2</th>\n",
       "      <th>avgp</th>\n",
       "      <th>avga</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hardware_Model</th>\n",
       "      <th>SDK_Version</th>\n",
       "      <th>Manufacture</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>575.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>466.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num_of_CPU_Cores  pLN1  p.2  pLN3  pt4  pi5  pe6  pLN7  p58  pLN9  \\\n",
       "0               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "1               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "2               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "3               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "4               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "\n",
       "       ...            avdu2  avgp      avga  Language  Hardware_Model  \\\n",
       "0      ...        88.200000   1.0  0.004412         0              40   \n",
       "1      ...        95.400000   1.0  0.004167         0              40   \n",
       "2      ...       575.333333   1.0  0.008333         0              40   \n",
       "3      ...       466.400000   1.0  0.008211         0              40   \n",
       "4      ...       121.800000   1.0  0.009804         0              40   \n",
       "\n",
       "   SDK_Version  Manufacture  Screen_Size  Time_Zone  Country_Code  \n",
       "0            3           18           23          7             1  \n",
       "1            3           18           23          7             1  \n",
       "2            3           18           23          7             1  \n",
       "3            3           18           23          7             1  \n",
       "4            3           18           23          7             1  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2310 entries, 0 to 2309\n",
      "Columns: 155 entries, Num_of_CPU_Cores to Country_Code\n",
      "dtypes: float64(148), int64(7)\n",
      "memory usage: 2.7 MB\n",
      "initial data info None\n",
      "data is (2310, 155)\n",
      "(2310, 155)\n",
      "(2310,)\n",
      "155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  36\n",
      "f1  0.9492344668318694\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  37\n",
      "f1  0.9484065501597969\n",
      "Accuracy: 0.9519480519480519\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  38\n",
      "f1  0.9490741509572679\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  39\n",
      "f1  0.9499877827799905\n",
      "Accuracy: 0.9532467532467532\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  40\n",
      "f1  0.9515412365412365\n",
      "Accuracy: 0.9545454545454545\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  41\n",
      "f1  0.953228640046822\n",
      "Accuracy: 0.9562770562770563\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  42\n",
      "f1  0.9537784870252404\n",
      "Accuracy: 0.9558441558441558\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  43\n",
      "f1  0.9527189116799507\n",
      "Accuracy: 0.9545454545454545\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  44\n",
      "f1  0.9528081730679133\n",
      "Accuracy: 0.9545454545454545\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  45\n",
      "f1  0.9535841935841937\n",
      "Accuracy: 0.9558441558441558\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  46\n",
      "f1  0.9519394962901456\n",
      "Accuracy: 0.9545454545454547\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  47\n",
      "f1  0.9543427351868911\n",
      "Accuracy: 0.9567099567099568\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  48\n",
      "f1  0.9517463416814065\n",
      "Accuracy: 0.9541125541125541\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  49\n",
      "f1  0.9519425091503013\n",
      "Accuracy: 0.9541125541125541\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  50\n",
      "f1  0.9524098844878065\n",
      "Accuracy: 0.9545454545454545\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  51\n",
      "f1  0.952883263922225\n",
      "Accuracy: 0.954978354978355\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  52\n",
      "f1  0.9541401888155135\n",
      "Accuracy: 0.9562770562770563\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  53\n",
      "f1  0.9513479377765093\n",
      "Accuracy: 0.9536796536796537\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  54\n",
      "f1  0.9507152371438086\n",
      "Accuracy: 0.9532467532467532\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  55\n",
      "f1  0.9499193192852475\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  56\n",
      "f1  0.9494773370250833\n",
      "Accuracy: 0.9519480519480519\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  57\n",
      "f1  0.9484578370445444\n",
      "Accuracy: 0.9510822510822511\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  58\n",
      "f1  0.9487659560539623\n",
      "Accuracy: 0.9510822510822511\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  59\n",
      "f1  0.9488434543132787\n",
      "Accuracy: 0.9510822510822511\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  60\n",
      "f1  0.9486923500063302\n",
      "Accuracy: 0.9506493506493505\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  61\n",
      "f1  0.9486923500063302\n",
      "Accuracy: 0.9506493506493505\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  62\n",
      "f1  0.9486549847741597\n",
      "Accuracy: 0.9506493506493507\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  63\n",
      "f1  0.9476411501239614\n",
      "Accuracy: 0.9497835497835497\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  64\n",
      "f1  0.9482011528917564\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  65\n",
      "f1  0.9483149784601276\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  66\n",
      "f1  0.9487389738688441\n",
      "Accuracy: 0.9506493506493505\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  67\n",
      "f1  0.948311493701104\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  68\n",
      "f1  0.9493231227646811\n",
      "Accuracy: 0.9510822510822511\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  69\n",
      "f1  0.9492512321733102\n",
      "Accuracy: 0.9510822510822511\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  70\n",
      "f1  0.9485180005462664\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  71\n",
      "f1  0.9472408793990155\n",
      "Accuracy: 0.9489177489177489\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  72\n",
      "f1  0.9467393933627701\n",
      "Accuracy: 0.9484848484848485\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  73\n",
      "f1  0.9485555858283131\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  74\n",
      "f1  0.9489554024618959\n",
      "Accuracy: 0.9506493506493505\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  75\n",
      "f1  0.9486414739661493\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  76\n",
      "f1  0.9492235470157547\n",
      "Accuracy: 0.9506493506493507\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  77\n",
      "f1  0.9503423632644411\n",
      "Accuracy: 0.9519480519480521\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  78\n",
      "f1  0.9464586940942938\n",
      "Accuracy: 0.9480519480519481\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  79\n",
      "f1  0.9482014534993908\n",
      "Accuracy: 0.9497835497835497\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  80\n",
      "f1  0.9480806441758955\n",
      "Accuracy: 0.9497835497835497\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  81\n",
      "f1  0.9491662757160727\n",
      "Accuracy: 0.9506493506493507\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  82\n",
      "f1  0.9508685599355455\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  83\n",
      "f1  0.9520817190707825\n",
      "Accuracy: 0.9532467532467532\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  84\n",
      "f1  0.9520799891989229\n",
      "Accuracy: 0.9532467532467532\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  85\n",
      "f1  0.9520354666219326\n",
      "Accuracy: 0.9532467532467533\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  86\n",
      "f1  0.9490213652072846\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  87\n",
      "f1  0.9505778750754829\n",
      "Accuracy: 0.9515151515151514\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  88\n",
      "f1  0.9505778750754829\n",
      "Accuracy: 0.9515151515151514\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  89\n",
      "f1  0.9498499449969033\n",
      "Accuracy: 0.9506493506493507\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  90\n",
      "f1  0.949125416999648\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  91\n",
      "f1  0.9492387812688564\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  92\n",
      "f1  0.9492578098593137\n",
      "Accuracy: 0.9502164502164501\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  93\n",
      "f1  0.9477971701501113\n",
      "Accuracy: 0.9484848484848485\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  94\n",
      "f1  0.9505324978052251\n",
      "Accuracy: 0.9515151515151515\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  95\n",
      "f1  0.9512546039818768\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  96\n",
      "f1  0.9505345736514567\n",
      "Accuracy: 0.9515151515151515\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  97\n",
      "f1  0.9485633038640557\n",
      "Accuracy: 0.9497835497835497\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  98\n",
      "f1  0.9498104982281331\n",
      "Accuracy: 0.9510822510822511\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  99\n",
      "f1  0.9494450049568461\n",
      "Accuracy: 0.9506493506493505\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  100\n",
      "f1  0.9495577061085083\n",
      "Accuracy: 0.9506493506493507\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  101\n",
      "f1  0.9521171469223416\n",
      "Accuracy: 0.9528138528138529\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  102\n",
      "f1  0.9523063694645055\n",
      "Accuracy: 0.9528138528138527\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  103\n",
      "f1  0.9513480204542084\n",
      "Accuracy: 0.9519480519480521\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  104\n",
      "f1  0.9496383016016324\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  105\n",
      "f1  0.9495691067272427\n",
      "Accuracy: 0.9502164502164503\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  106\n",
      "f1  0.9504730512675508\n",
      "Accuracy: 0.9510822510822511\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  107\n",
      "f1  0.9487353949844399\n",
      "Accuracy: 0.9493506493506493\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  108\n",
      "f1  0.9504401837022158\n",
      "Accuracy: 0.9510822510822511\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  109\n",
      "f1  0.9499719976992704\n",
      "Accuracy: 0.9506493506493505\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  110\n",
      "f1  0.9485521188767942\n",
      "Accuracy: 0.9493506493506494\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  111\n",
      "f1  0.948976629431175\n",
      "Accuracy: 0.9497835497835497\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  112\n",
      "f1  0.9486774480930326\n",
      "Accuracy: 0.9493506493506493\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  113\n",
      "f1  0.9480758563226097\n",
      "Accuracy: 0.9489177489177489\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  114\n",
      "f1  0.9476484049860673\n",
      "Accuracy: 0.9484848484848485\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  115\n",
      "f1  0.9489259369778852\n",
      "Accuracy: 0.9497835497835497\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  116\n",
      "f1  0.9489259369778852\n",
      "Accuracy: 0.9497835497835497\n",
      "metrics\n",
      "metrics\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  117\n",
      "f1  0.9484427837674592\n",
      "Accuracy: 0.9493506493506494\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  118\n",
      "f1  0.948716564820461\n",
      "Accuracy: 0.94978354978355\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  119\n",
      "f1  0.9487310957440828\n",
      "Accuracy: 0.9497835497835497\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  120\n",
      "f1  0.9482921407596733\n",
      "Accuracy: 0.9493506493506494\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  121\n",
      "f1  0.9469409378500288\n",
      "Accuracy: 0.9480519480519479\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  122\n",
      "f1  0.9460728881508101\n",
      "Accuracy: 0.9471861471861471\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  123\n",
      "f1  0.9461231409283357\n",
      "Accuracy: 0.9471861471861471\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  124\n",
      "f1  0.9456751041166627\n",
      "Accuracy: 0.9467532467532468\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  125\n",
      "f1  0.9469803484012804\n",
      "Accuracy: 0.9480519480519481\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  126\n",
      "f1  0.9483169987639049\n",
      "Accuracy: 0.9493506493506494\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  127\n",
      "f1  0.9464749158828608\n",
      "Accuracy: 0.9476190476190478\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  128\n",
      "f1  0.9464717372433185\n",
      "Accuracy: 0.9476190476190476\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  129\n",
      "f1  0.9468853529968884\n",
      "Accuracy: 0.9480519480519481\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  130\n",
      "f1  0.945924726321976\n",
      "Accuracy: 0.9471861471861474\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  131\n",
      "f1  0.9464373161852153\n",
      "Accuracy: 0.9476190476190476\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  132\n",
      "f1  0.9460074430280695\n",
      "Accuracy: 0.9471861471861471\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  133\n",
      "f1  0.944792216950353\n",
      "Accuracy: 0.9463203463203463\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  134\n",
      "f1  0.9438900007644732\n",
      "Accuracy: 0.9454545454545455\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  135\n",
      "f1  0.9443733861419116\n",
      "Accuracy: 0.9458874458874458\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  136\n",
      "f1  0.9439374584332569\n",
      "Accuracy: 0.9454545454545455\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  137\n",
      "f1  0.944364589234719\n",
      "Accuracy: 0.9458874458874458\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  138\n",
      "f1  0.943361890634618\n",
      "Accuracy: 0.945021645021645\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  139\n",
      "f1  0.941980501461021\n",
      "Accuracy: 0.9437229437229437\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  140\n",
      "f1  0.9419826911146119\n",
      "Accuracy: 0.9437229437229437\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  141\n",
      "f1  0.9420262565717111\n",
      "Accuracy: 0.9437229437229437\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  142\n",
      "f1  0.9409351398961789\n",
      "Accuracy: 0.9424242424242424\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  143\n",
      "f1  0.9404519866857528\n",
      "Accuracy: 0.941991341991342\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  144\n",
      "f1  0.9404519866857528\n",
      "Accuracy: 0.941991341991342\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  145\n",
      "f1  0.9414025512726811\n",
      "Accuracy: 0.9428571428571428\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  146\n",
      "f1  0.9413395839369866\n",
      "Accuracy: 0.9428571428571428\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  147\n",
      "f1  0.9398013226994772\n",
      "Accuracy: 0.9415584415584416\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  148\n",
      "f1  0.9398013226994772\n",
      "Accuracy: 0.9415584415584416\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  149\n",
      "f1  0.9389294672821672\n",
      "Accuracy: 0.9406926406926408\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  150\n",
      "f1  0.9380103863630863\n",
      "Accuracy: 0.9398268398268398\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  151\n",
      "f1  0.9375744586544312\n",
      "Accuracy: 0.9393939393939394\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  152\n",
      "f1  0.9370695955521656\n",
      "Accuracy: 0.9389610389610388\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  153\n",
      "f1  0.9370774664691275\n",
      "Accuracy: 0.938961038961039\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  154\n",
      "f1  0.9376894951331043\n",
      "Accuracy: 0.9393939393939394\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  155\n",
      "f1  0.9363920047447047\n",
      "Accuracy: 0.9380952380952381\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAEDCAYAAADwacP6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc86b1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import lsanomaly\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn import utils  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "\n",
    "# import the CSV from http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "# this will return a pandas dataframe.\n",
    "data = pd.read_csv('C:/Users/S/Documents/PY/increased30featuresfile.csv', low_memory=False)\n",
    "'''data.loc[data['UUID'] == \"RVTNB1502866560357\", \"attack\"] = 1  \n",
    "data.loc[data['UUID'] != \"RVTNB1502866560357\", \"attack\"] = -1\n",
    "df_majority = data[data['attack']==-1]\n",
    "df_minority = data[data['attack']==1]\n",
    "from sklearn.utils import resample\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=830,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "#print(data['attack'].value_counts())'''\n",
    "\n",
    "#target=np.array(target)\n",
    "#target = pd.DataFrame(target,columns=['attack'])\n",
    "\n",
    "#data.drop([\"UUID\"], axis=1, inplace=True)\n",
    "categorical_columns=[\"UUID\",\"Language\",\"Hardware_Model\",\"SDK_Version\",\"Manufacture\",\"Screen_Size\",\"Time_Zone\",\"Country_Code\"]\n",
    "cate_data = data[categorical_columns]\n",
    "\n",
    "#for col in data.columns.values:\n",
    "#    print(col, data[col].unique())\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "def label_encode(cate_data, columns):\n",
    "    for col in columns:\n",
    "        le = LabelEncoder()\n",
    "        col_values_unique = list(cate_data[col].unique())\n",
    "        le_fitted = le.fit(col_values_unique)\n",
    " \n",
    "        col_values = list(cate_data[col].values)\n",
    "        le.classes_\n",
    "        col_values_transformed = le.transform(col_values)\n",
    "        cate_data[col] = col_values_transformed\n",
    " \n",
    "to_be_encoded_cols = cate_data.columns.values\n",
    "label_encode(cate_data, to_be_encoded_cols)\n",
    "display(cate_data.head())\n",
    "target=cate_data['UUID']\n",
    "target=np.array(target)\n",
    "#target = pd.DataFrame(target)\n",
    "#target=target1.values\n",
    "\n",
    "data.drop([\"UUID\",\"Language\",\"Hardware_Model\",\"SDK_Version\",\"Manufacture\",\"Screen_Size\",\"Time_Zone\",\"Country_Code\"], axis=1, inplace=True)\n",
    "data=pd.concat([data,cate_data], axis=1)\n",
    "data.drop([\"UUID\"], axis=1, inplace=True)\n",
    "#display(scaled_data.head())\n",
    "\n",
    "\n",
    "# check the shape for sanity checking.\n",
    "data.shape\n",
    "display(data.head())\n",
    "print(\"initial data info\",data.info())\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"data is\",data.shape)\n",
    "from skfeature.function.information_theoretical_based import LCSI\n",
    "from skfeature.function.information_theoretical_based import MRMR\n",
    "\n",
    "from skfeature.utility.entropy_estimators import *\n",
    "import scipy.io\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaled_data=data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaleddata= pd.DataFrame(scaled_data)\n",
    "scaled_data=np.array(scaled_data)\n",
    "\n",
    "print(scaled_data.shape)\n",
    "print(target.shape)\n",
    "#display(scaled_data.head())\n",
    "\n",
    "#display(target.head())\n",
    "#idx=MRMR.mrmr(scaled_data,target,n_selected_features=50)\n",
    "'''from sklearn import cross_validation\n",
    "ss = cross_validation.KFold(5, n_folds=5, shuffle=True)\n",
    "correct = 0\n",
    "print(\"scaled data details - \",scaled_data.info())\n",
    "print(\"target data details - \",target.info())\n",
    "for train, test in ss:\n",
    "    #print(scaled_data[train])\n",
    "    #print(target[train])\n",
    "        # obtain the index of each feature on the training set\n",
    "    idx,_,_ = MRMR.mrmr(scaled_data[train], target[train], n_selected_features=50)\n",
    "\n",
    "        # obtain the dataset on the selected features\n",
    "    features = scaled_data[:, idx[0:50]]\n",
    "print(features)    '''\n",
    "'''skb= SVC(kernel=\"linear\")\n",
    "rfe = RFE(estimator=skb, n_features_to_select=70)\n",
    "rfe=rfe.fit(scaleddata,target)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "skft = StratifiedKFold(n_splits=5,shuffle=True,random_state=36851234)\n",
    "for train, test in skft:\n",
    "    X_train,X_test=scaled_data.iloc[train],scaled_data.iloc[test]\n",
    "    Y_train,y_test=target.iloc[train],target.iloc[test]\n",
    "    model1 = svm.OneClassSVM(nu=nu, kernel='rbf', gamma=0.10000000000000001)  \n",
    "    model1.fit(X_train, Y_train)\n",
    "    scores = cross_val_score(model1,X_test,y_test, cv=5, scoring='accuracy')\n",
    "    print(scores)\n",
    "print(scores.mean())'''\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ss = cross_validation.KFold(5, n_folds=5, shuffle=True)\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5,random_state=36851234)\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=36851234)\n",
    "clf=SVC(kernel='linear')\n",
    "#clf = svm.SVC(decision_function_shape='ovo')    # linear SVM\n",
    "correct = 0\n",
    "fscoreTotal =0\n",
    "print(scaled_data.shape[1])\n",
    "plt.figure(figsize=(16, 8))\n",
    "accuracy = plt.subplot(221)\n",
    "\n",
    "x=np.array([])\n",
    "y=np.array([])\n",
    "f1val=np.array([])\n",
    "numoffeatures= lambda start, end: range(start, end+1)\n",
    "for i in numoffeatures(36,scaled_data.shape[1]):\n",
    "    for train, test in skf.split(scaled_data,target):\n",
    "        # obtain the index of each feature on the training set\n",
    "        idx,_,_ = MRMR.mrmr(scaled_data[train], target[train], n_selected_features=i)\n",
    "\n",
    "        # obtain the dataset on the selected features\n",
    "        features = scaled_data[:, idx[0:i]]\n",
    "        #print(target[train])\n",
    "        # train a classification model with the selected features on the training dataset\n",
    "        clf.fit(features[train], target[train])\n",
    "\n",
    "        # predict the class labels of test data\n",
    "        y_predict = clf.predict(features[test])\n",
    "        print(\"metrics\")\n",
    "        # obtain the classification accuracy on the test data\n",
    "        acc = accuracy_score(target[test], y_predict)\n",
    "        correct = correct + acc\n",
    "        fscore=f1_score(target[test], y_predict,average='weighted')\n",
    "        fscoreTotal=fscoreTotal+fscore\n",
    "        #print(\"fsc \",f1_score(target[test], y_predict,average='weighted'))\n",
    "        #print(\"conf mat \",confusion_matrix(target[test],y_predict))\n",
    "        #print(\"ACCURACY: \", (accuracy_score(target[test], y_predict)))\n",
    "        #report = classification_report(target[test], y_predict)\n",
    "        #print(report)\n",
    "    x=np.append(x,i)\n",
    "    accscores=float(correct)/5\n",
    "    f1scores=float(fscoreTotal)/5\n",
    "    y=np.append(y,accscores)\n",
    "    f1val=np.append(f1val,f1scores)\n",
    "    np.savetxt('f1val.txt', (y,f1val), fmt='%.5g', delimiter=',', newline='\\n')\n",
    "    print(\"loop \",i)\n",
    "    print(\"f1 \",f1scores)\n",
    "    # output the average classification accuracy over all 10 folds\n",
    "    print(\"Accuracy:\", accscores)\n",
    "    fscore=0\n",
    "    acc=0\n",
    "    correct=0\n",
    "    fscoreTotal=0\n",
    "##svc=SelectKBest(mutual_info_classif, k=50).fit_transform(data,target)\n",
    "#svc = SVC(kernel=\"linear\")\n",
    "#rfe = RFE(estimator=svc, n_features_to_select=10)\n",
    "#rfe.fit(data, target)\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, m*x + b, '-')\n",
    "accuracy.plot(x,y)\n",
    "accuracy.set_title(\"mRMR feature selection\")\n",
    "accuracy.set_xlim(36, scaled_data.shape[1])\n",
    "accuracy.set_xlabel(\"Number of Features\")\n",
    "accuracy.set_ylim(0.9, 1)\n",
    "accuracy.set_ylabel(\"Classification Accuracy\")\n",
    "f1=plt.subplot(222)\n",
    "n, c = np.polyfit(x, f1val, 1)\n",
    "plt.plot(x, f1val, '.')\n",
    "plt.plot(x, n*x + c, '-')\n",
    "f1.plot(x,f1val)\n",
    "f1.set_title(\"mRMR feature selection\")\n",
    "f1.set_xlim(36, scaled_data.shape[1])\n",
    "f1.set_xlabel(\"Number of Features\")\n",
    "f1.set_ylim(0.9, 1)\n",
    "f1.set_ylabel(\"Classification F1 Score\")\n",
    "plt.show()\n",
    "print(\"here\")\n",
    "#score = svc.score(data, target)\n",
    "##print(svc)\n",
    "#ranking = rfe.feature_importances_\n",
    "#print(\"no of feat\",ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hardware_Model</th>\n",
       "      <th>SDK_Version</th>\n",
       "      <th>Manufacture</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UUID  Language  Hardware_Model  SDK_Version  Manufacture  Screen_Size  \\\n",
       "0    48         0              40            3           18           23   \n",
       "1    48         0              40            3           18           23   \n",
       "2    48         0              40            3           18           23   \n",
       "3    48         0              40            3           18           23   \n",
       "4    48         0              40            3           18           23   \n",
       "\n",
       "   Time_Zone  Country_Code  \n",
       "0          7             1  \n",
       "1          7             1  \n",
       "2          7             1  \n",
       "3          7             1  \n",
       "4          7             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_of_CPU_Cores</th>\n",
       "      <th>pLN1</th>\n",
       "      <th>p.2</th>\n",
       "      <th>pLN3</th>\n",
       "      <th>pt4</th>\n",
       "      <th>pi5</th>\n",
       "      <th>pe6</th>\n",
       "      <th>pLN7</th>\n",
       "      <th>p58</th>\n",
       "      <th>pLN9</th>\n",
       "      <th>...</th>\n",
       "      <th>avdu2</th>\n",
       "      <th>avgp</th>\n",
       "      <th>avga</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hardware_Model</th>\n",
       "      <th>SDK_Version</th>\n",
       "      <th>Manufacture</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>575.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>466.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num_of_CPU_Cores  pLN1  p.2  pLN3  pt4  pi5  pe6  pLN7  p58  pLN9  \\\n",
       "0               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "1               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "2               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "3               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "4               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "\n",
       "       ...            avdu2  avgp      avga  Language  Hardware_Model  \\\n",
       "0      ...        88.200000   1.0  0.004412         0              40   \n",
       "1      ...        95.400000   1.0  0.004167         0              40   \n",
       "2      ...       575.333333   1.0  0.008333         0              40   \n",
       "3      ...       466.400000   1.0  0.008211         0              40   \n",
       "4      ...       121.800000   1.0  0.009804         0              40   \n",
       "\n",
       "   SDK_Version  Manufacture  Screen_Size  Time_Zone  Country_Code  \n",
       "0            3           18           23          7             1  \n",
       "1            3           18           23          7             1  \n",
       "2            3           18           23          7             1  \n",
       "3            3           18           23          7             1  \n",
       "4            3           18           23          7             1  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2310 entries, 0 to 2309\n",
      "Columns: 155 entries, Num_of_CPU_Cores to Country_Code\n",
      "dtypes: float64(148), int64(7)\n",
      "memory usage: 2.7 MB\n",
      "initial data info None\n",
      "data is (2310, 155)\n",
      "(2310, 155)\n",
      "(2310,)\n",
      "155\n",
      "metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  3\n",
      "f1  0.45097666915305396\n",
      "Accuracy: 0.4974025974025974\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  4\n",
      "f1  0.7000745342247494\n",
      "Accuracy: 0.7255411255411255\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  5\n",
      "f1  0.7727978434433743\n",
      "Accuracy: 0.7878787878787878\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  6\n",
      "f1  0.7817692976745689\n",
      "Accuracy: 0.7961038961038961\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  7\n",
      "f1  0.8138026127349034\n",
      "Accuracy: 0.8264069264069264\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  8\n",
      "f1  0.8796536611767202\n",
      "Accuracy: 0.8857142857142858\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  9\n",
      "f1  0.9172620327728687\n",
      "Accuracy: 0.9203463203463202\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  10\n",
      "f1  0.919242195467317\n",
      "Accuracy: 0.922077922077922\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  11\n",
      "f1  0.9205724414881666\n",
      "Accuracy: 0.9233766233766234\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  12\n",
      "f1  0.9187067424643315\n",
      "Accuracy: 0.9212121212121211\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  13\n",
      "f1  0.9215458946541333\n",
      "Accuracy: 0.9238095238095237\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  14\n",
      "f1  0.9284576951870186\n",
      "Accuracy: 0.9303030303030303\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  15\n",
      "f1  0.9306790236421133\n",
      "Accuracy: 0.9324675324675326\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  16\n",
      "f1  0.9442567446224317\n",
      "Accuracy: 0.9463203463203463\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  17\n",
      "f1  0.9439370802357816\n",
      "Accuracy: 0.9458874458874458\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  18\n",
      "f1  0.944007918488438\n",
      "Accuracy: 0.9458874458874458\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  19\n",
      "f1  0.9458406600614392\n",
      "Accuracy: 0.9476190476190476\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  20\n",
      "f1  0.9509544784220108\n",
      "Accuracy: 0.9528138528138529\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  21\n",
      "f1  0.9505246052648649\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  22\n",
      "f1  0.9505642248422997\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  23\n",
      "f1  0.9505804296713386\n",
      "Accuracy: 0.9528138528138529\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  24\n",
      "f1  0.9496461547110897\n",
      "Accuracy: 0.9519480519480519\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  25\n",
      "f1  0.9510583644349877\n",
      "Accuracy: 0.9532467532467532\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  26\n",
      "f1  0.951148952058043\n",
      "Accuracy: 0.9536796536796537\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  27\n",
      "f1  0.9501546072974645\n",
      "Accuracy: 0.9528138528138527\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  28\n",
      "f1  0.9497030242484789\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  29\n",
      "f1  0.9497363675285753\n",
      "Accuracy: 0.9523809523809523\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  30\n",
      "f1  0.9509395582772207\n",
      "Accuracy: 0.9536796536796537\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  31\n",
      "f1  0.9499536178107606\n",
      "Accuracy: 0.9528138528138529\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  32\n",
      "f1  0.9530103013869249\n",
      "Accuracy: 0.9558441558441558\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  33\n",
      "f1  0.9516063373855582\n",
      "Accuracy: 0.9545454545454545\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "metrics\n",
      "loop  34\n",
      "f1  0.9504334842646532\n",
      "Accuracy: 0.9536796536796537\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAEDCAYAAADwacP6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREREREYsb/A8gah8P7lOUGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5b8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import lsanomaly\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn import utils  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "\n",
    "# import the CSV from http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "# this will return a pandas dataframe.\n",
    "data = pd.read_csv('C:/Users/S/Documents/PY/increased30featuresfile.csv', low_memory=False)\n",
    "'''data.loc[data['UUID'] == \"RVTNB1502866560357\", \"attack\"] = 1  \n",
    "data.loc[data['UUID'] != \"RVTNB1502866560357\", \"attack\"] = -1\n",
    "df_majority = data[data['attack']==-1]\n",
    "df_minority = data[data['attack']==1]\n",
    "from sklearn.utils import resample\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=830,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "#print(data['attack'].value_counts())'''\n",
    "\n",
    "#target=np.array(target)\n",
    "#target = pd.DataFrame(target,columns=['attack'])\n",
    "\n",
    "#data.drop([\"UUID\"], axis=1, inplace=True)\n",
    "categorical_columns=[\"UUID\",\"Language\",\"Hardware_Model\",\"SDK_Version\",\"Manufacture\",\"Screen_Size\",\"Time_Zone\",\"Country_Code\"]\n",
    "cate_data = data[categorical_columns]\n",
    "\n",
    "#for col in data.columns.values:\n",
    "#    print(col, data[col].unique())\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "def label_encode(cate_data, columns):\n",
    "    for col in columns:\n",
    "        le = LabelEncoder()\n",
    "        col_values_unique = list(cate_data[col].unique())\n",
    "        le_fitted = le.fit(col_values_unique)\n",
    " \n",
    "        col_values = list(cate_data[col].values)\n",
    "        le.classes_\n",
    "        col_values_transformed = le.transform(col_values)\n",
    "        cate_data[col] = col_values_transformed\n",
    " \n",
    "to_be_encoded_cols = cate_data.columns.values\n",
    "label_encode(cate_data, to_be_encoded_cols)\n",
    "display(cate_data.head())\n",
    "target=cate_data['UUID']\n",
    "target=np.array(target)\n",
    "#target = pd.DataFrame(target)\n",
    "#target=target1.values\n",
    "\n",
    "data.drop([\"UUID\",\"Language\",\"Hardware_Model\",\"SDK_Version\",\"Manufacture\",\"Screen_Size\",\"Time_Zone\",\"Country_Code\"], axis=1, inplace=True)\n",
    "data=pd.concat([data,cate_data], axis=1)\n",
    "data.drop([\"UUID\"], axis=1, inplace=True)\n",
    "#display(scaled_data.head())\n",
    "\n",
    "\n",
    "# check the shape for sanity checking.\n",
    "data.shape\n",
    "display(data.head())\n",
    "print(\"initial data info\",data.info())\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"data is\",data.shape)\n",
    "from skfeature.function.information_theoretical_based import LCSI\n",
    "from skfeature.function.information_theoretical_based import MRMR\n",
    "\n",
    "from skfeature.utility.entropy_estimators import *\n",
    "import scipy.io\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaled_data=data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaleddata= pd.DataFrame(scaled_data)\n",
    "scaled_data=np.array(scaled_data)\n",
    "\n",
    "print(scaled_data.shape)\n",
    "print(target.shape)\n",
    "#display(scaled_data.head())\n",
    "\n",
    "#display(target.head())\n",
    "#idx=MRMR.mrmr(scaled_data,target,n_selected_features=50)\n",
    "'''from sklearn import cross_validation\n",
    "ss = cross_validation.KFold(5, n_folds=5, shuffle=True)\n",
    "correct = 0\n",
    "print(\"scaled data details - \",scaled_data.info())\n",
    "print(\"target data details - \",target.info())\n",
    "for train, test in ss:\n",
    "    #print(scaled_data[train])\n",
    "    #print(target[train])\n",
    "        # obtain the index of each feature on the training set\n",
    "    idx,_,_ = MRMR.mrmr(scaled_data[train], target[train], n_selected_features=50)\n",
    "\n",
    "        # obtain the dataset on the selected features\n",
    "    features = scaled_data[:, idx[0:50]]\n",
    "print(features)    '''\n",
    "'''skb= SVC(kernel=\"linear\")\n",
    "rfe = RFE(estimator=skb, n_features_to_select=70)\n",
    "rfe=rfe.fit(scaleddata,target)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "skft = StratifiedKFold(n_splits=5,shuffle=True,random_state=36851234)\n",
    "for train, test in skft:\n",
    "    X_train,X_test=scaled_data.iloc[train],scaled_data.iloc[test]\n",
    "    Y_train,y_test=target.iloc[train],target.iloc[test]\n",
    "    model1 = svm.OneClassSVM(nu=nu, kernel='rbf', gamma=0.10000000000000001)  \n",
    "    model1.fit(X_train, Y_train)\n",
    "    scores = cross_val_score(model1,X_test,y_test, cv=5, scoring='accuracy')\n",
    "    print(scores)\n",
    "print(scores.mean())'''\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ss = cross_validation.KFold(5, n_folds=5, shuffle=True)\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5,random_state=36851234)\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=36851234)\n",
    "clf=SVC(kernel='linear')\n",
    "#clf = svm.SVC(decision_function_shape='ovo')    # linear SVM\n",
    "correct = 0\n",
    "fscoreTotal =0\n",
    "print(scaled_data.shape[1])\n",
    "plt.figure(figsize=(16, 8))\n",
    "accuracy = plt.subplot(221)\n",
    "\n",
    "x=np.array([])\n",
    "y=np.array([])\n",
    "f1val=np.array([])\n",
    "numoffeatures= lambda start, end: range(start, end+1)\n",
    "for i in numoffeatures(3,34):\n",
    "    for train, test in skf.split(scaled_data,target):\n",
    "        # obtain the index of each feature on the training set\n",
    "        idx,_,_ = MRMR.mrmr(scaled_data[train], target[train], n_selected_features=i)\n",
    "\n",
    "        # obtain the dataset on the selected features\n",
    "        features = scaled_data[:, idx[0:i]]\n",
    "        #print(target[train])\n",
    "        # train a classification model with the selected features on the training dataset\n",
    "        clf.fit(features[train], target[train])\n",
    "\n",
    "        # predict the class labels of test data\n",
    "        y_predict = clf.predict(features[test])\n",
    "        print(\"metrics\")\n",
    "        # obtain the classification accuracy on the test data\n",
    "        acc = accuracy_score(target[test], y_predict)\n",
    "        correct = correct + acc\n",
    "        fscore=f1_score(target[test], y_predict,average='weighted')\n",
    "        fscoreTotal=fscoreTotal+fscore\n",
    "        #print(\"fsc \",f1_score(target[test], y_predict,average='weighted'))\n",
    "        #print(\"conf mat \",confusion_matrix(target[test],y_predict))\n",
    "        #print(\"ACCURACY: \", (accuracy_score(target[test], y_predict)))\n",
    "        #report = classification_report(target[test], y_predict)\n",
    "        #print(report)\n",
    "    x=np.append(x,i)\n",
    "    accscores=float(correct)/5\n",
    "    f1scores=float(fscoreTotal)/5\n",
    "    y=np.append(y,accscores)\n",
    "    f1val=np.append(f1val,f1scores)\n",
    "    np.savetxt('f1val.txt', (y,f1val), fmt='%.5g', delimiter=',', newline='\\n')\n",
    "    print(\"loop \",i)\n",
    "    print(\"f1 \",f1scores)\n",
    "    # output the average classification accuracy over all 10 folds\n",
    "    print(\"Accuracy:\", accscores)\n",
    "    fscore=0\n",
    "    acc=0\n",
    "    correct=0\n",
    "    fscoreTotal=0\n",
    "##svc=SelectKBest(mutual_info_classif, k=50).fit_transform(data,target)\n",
    "#svc = SVC(kernel=\"linear\")\n",
    "#rfe = RFE(estimator=svc, n_features_to_select=10)\n",
    "#rfe.fit(data, target)\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, m*x + b, '-')\n",
    "accuracy.plot(x,y)\n",
    "accuracy.set_title(\"mRMR feature selection\")\n",
    "accuracy.set_xlim(3, 34)\n",
    "accuracy.set_xlabel(\"Number of Features\")\n",
    "accuracy.set_ylim(0.9, 1)\n",
    "accuracy.set_ylabel(\"Classification Accuracy\")\n",
    "f1=plt.subplot(222)\n",
    "n, c = np.polyfit(x, f1val, 1)\n",
    "plt.plot(x, f1val, '.')\n",
    "plt.plot(x, n*x + c, '-')\n",
    "f1.plot(x,f1val)\n",
    "f1.set_title(\"mRMR feature selection\")\n",
    "f1.set_xlim(3, 34)\n",
    "f1.set_xlabel(\"Number of Features\")\n",
    "f1.set_ylim(0.9, 1)\n",
    "f1.set_ylabel(\"Classification F1 Score\")\n",
    "plt.show()\n",
    "print(\"here\")\n",
    "#score = svc.score(data, target)\n",
    "##print(svc)\n",
    "#ranking = rfe.feature_importances_\n",
    "#print(\"no of feat\",ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strtd\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAEDCAYAAAD6NW2oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMzMzKwt/BegZvWMg8t/1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8ee6128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display\n",
    "print(\"strtd\")\n",
    "plt.figure(figsize=(16, 8))\n",
    "accuracy = plt.subplot(221)\n",
    "x=np.array([])\n",
    "numoffeatures= lambda start, end: range(start, end+1)\n",
    "for i in numoffeatures(3,155):\n",
    "    x=np.append(x,i)\n",
    "y=np.array([0.7974,0.8,0.81255,0.80433,0.81498,0.8132,0.81368,0.8197,0.8197,0.80749,0.80835,0.81212,0.80996,0.81039,0.80693,0.80779,0.81861,0.83377,0.85974,0.86537,0.87792,0.85974,0.86537,0.87792,0.87922,0.89004,0.88485,0.8961,0.90433,0.92554,0.9254,0.9241,0.9258,0.9248,0.9298,0.9284,0.9298,0.9384,0.93788,0.9361,0.93641,0.93571,0.92035,0.92208,0.92338,0.92121,0.92381,0.9303,0.93247,0.94632,0.94589,0.94589,0.94762,0.95411,0.95411,0.95108,0.95108,0.95065,0.95065,0.95065,0.94978,0.95022,0.95022,0.95065,0.95022,0.95108,0.95108,0.95022,0.94892,0.94848,0.95022,0.95065,0.95022,0.95065,0.95195,0.94805,0.94978,0.94978,0.95065,0.95238,0.95325,0.95325,0.95325,0.95022,0.95152,0.95152,0.95065,0.95022,0.95022,0.95022,0.94848,0.95152,0.95238,0.95152,0.94978,0.95108,0.95065,0.95065,0.95281,0.95281,0.95195,0.95022,0.95022,0.95108,0.94935,0.95108,0.95065,0.94935,0.94978,0.94935,0.94892,0.94848,0.94978,0.94978,0.94935,0.94978,0.94978,0.94935,0.94805,0.94719,0.94719,0.94675,0.94805,0.94935,0.94762,0.94762,0.94805,0.94719,0.94762,0.94719,0.94632,0.94545,0.94589,0.94545,0.94589,0.94502,0.94372,0.94372,0.94372,0.94242,0.94199,0.94199,0.94286,0.94286,0.94156,0.94156,0.94069,0.93983,0.93939,0.93896,0.93896,0.93939,0.9381])\n",
    "f1val=np.array([0.75098,0.74366,0.76685,0.78123,0.77407,0.8319,0.83955,0.83066,0.84774,0.84783,0.84807,0.84861,0.84513,0.83198,0.83457,0.83003,0.83005,0.84297,0.84085,0.84721,0.8575,0.86787,0.86867,0.88109,0.88595,0.88845,0.89735,0.90007,0.9028,0.90177,0.9038,0.90965,0.90726,0.90924,0.9057,0.90871,0.91155,0.92846,0.92068,0.92426,0.92394,0.92401,0.92584,0.92095,0.9206,0.93115,0.93015,0.9397,0.92974,0.93094,0.92995,0.95378,0.94992,0.94948,0.94846,0.94877,0.94884,0.94869,0.94869,0.94865,0.94764,0.9482,0.94831,0.94874,0.94831,0.94932,0.94925,0.94852,0.94724,0.94674,0.94856,0.94896,0.94864,0.94922,0.95034,0.94646,0.9482,0.94808,0.94917,0.95087,0.95208,0.95208,0.95204,0.94902,0.95058,0.95058,0.94985,0.94913,0.94924,0.94926,0.9478,0.95053,0.95125,0.95053,0.94856,0.94981,0.94945,0.94956,0.95212,0.95231,0.95135,0.94964,0.94957,0.95047,0.94874,0.95044,0.94997,0.94855,0.94898,0.94868,0.94808,0.94765,0.94893,0.94893,0.94844,0.94872,0.94873,0.94829,0.94694,0.94607,0.94612,0.94568,0.94698,0.94832,0.94647,0.94647,0.94689,0.94592,0.94644,0.94601,0.94479,0.94389,0.94437,0.94394,0.94436,0.94336,0.94198,0.94198,0.94203,0.94094,0.94045,0.93045,0.9314,0.93134,0.9298,0.9298,0.93893,0.92801,0.92757,0.92707,0.92708,0.92769,0.92639])\n",
    "    \n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, m*x + b, '-')\n",
    "accuracy.plot(x,y)\n",
    "accuracy.set_title(\"Before feature selection\")\n",
    "accuracy.set_xlim(3, 155)\n",
    "accuracy.set_xlabel(\"Number of Features\")\n",
    "accuracy.set_ylim(0.8, 1)\n",
    "accuracy.set_ylabel(\"Classification Accuracy\")\n",
    "f1=plt.subplot(222)\n",
    "n, c = np.polyfit(x, f1val, 1)\n",
    "plt.plot(x, f1val, '.')\n",
    "plt.plot(x, n*x + c, '-')\n",
    "f1.plot(x,f1val)\n",
    "f1.set_title(\"Before feature selection\")\n",
    "f1.set_xlim(3, 155)\n",
    "f1.set_xlabel(\"Number of Features\")\n",
    "f1.set_ylim(0.8, 1)\n",
    "f1.set_ylabel(\"Classification F1 Score\")\n",
    "plt.show()\n",
    "print(\"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hardware_Model</th>\n",
       "      <th>SDK_Version</th>\n",
       "      <th>Manufacture</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UUID  Language  Hardware_Model  SDK_Version  Manufacture  Screen_Size  \\\n",
       "0    48         0              40            3           18           23   \n",
       "1    48         0              40            3           18           23   \n",
       "2    48         0              40            3           18           23   \n",
       "3    48         0              40            3           18           23   \n",
       "4    48         0              40            3           18           23   \n",
       "\n",
       "   Time_Zone  Country_Code  \n",
       "0          7             1  \n",
       "1          7             1  \n",
       "2          7             1  \n",
       "3          7             1  \n",
       "4          7             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_of_CPU_Cores</th>\n",
       "      <th>pLN1</th>\n",
       "      <th>p.2</th>\n",
       "      <th>pLN3</th>\n",
       "      <th>pt4</th>\n",
       "      <th>pi5</th>\n",
       "      <th>pe6</th>\n",
       "      <th>pLN7</th>\n",
       "      <th>p58</th>\n",
       "      <th>pLN9</th>\n",
       "      <th>...</th>\n",
       "      <th>avdu2</th>\n",
       "      <th>avgp</th>\n",
       "      <th>avga</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hardware_Model</th>\n",
       "      <th>SDK_Version</th>\n",
       "      <th>Manufacture</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>575.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>466.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num_of_CPU_Cores  pLN1  p.2  pLN3  pt4  pi5  pe6  pLN7  p58  pLN9  \\\n",
       "0               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "1               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "2               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "3               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "4               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "\n",
       "       ...            avdu2  avgp      avga  Language  Hardware_Model  \\\n",
       "0      ...        88.200000   1.0  0.004412         0              40   \n",
       "1      ...        95.400000   1.0  0.004167         0              40   \n",
       "2      ...       575.333333   1.0  0.008333         0              40   \n",
       "3      ...       466.400000   1.0  0.008211         0              40   \n",
       "4      ...       121.800000   1.0  0.009804         0              40   \n",
       "\n",
       "   SDK_Version  Manufacture  Screen_Size  Time_Zone  Country_Code  \n",
       "0            3           18           23          7             1  \n",
       "1            3           18           23          7             1  \n",
       "2            3           18           23          7             1  \n",
       "3            3           18           23          7             1  \n",
       "4            3           18           23          7             1  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2310 entries, 0 to 2309\n",
      "Columns: 155 entries, Num_of_CPU_Cores to Country_Code\n",
      "dtypes: float64(148), int64(7)\n",
      "memory usage: 2.7 MB\n",
      "initial data info None\n",
      "data is (2310, 155)\n",
      "(2310, 155)\n",
      "(2310,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      0.83      0.91         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.50      0.83      0.62         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       0.86      1.00      0.92         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       1.00      0.83      0.91         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.00      0.00      0.00         6\n",
      "         28       0.67      1.00      0.80         6\n",
      "         29       0.67      0.33      0.44         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.56      0.83      0.67         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       0.83      0.83      0.83         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.75      1.00      0.86         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.60      1.00      0.75         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      0.33      0.50         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       0.86      1.00      0.92         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      0.50      0.67         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       0.83      0.83      0.83         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.95      0.95      0.94       462\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      0.83      0.91         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.71      0.83      0.77         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       1.00      0.83      0.91         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       0.86      1.00      0.92         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       1.00      0.83      0.91         6\n",
      "         28       0.75      1.00      0.86         6\n",
      "         29       0.50      0.50      0.50         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.50      0.50      0.50         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      0.83      0.91         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.83      0.83      0.83         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.75      1.00      0.86         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      0.67      0.80         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       0.86      1.00      0.92         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      0.67      0.80         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       0.86      1.00      0.92         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.97      0.97      0.97       462\n",
      "\n",
      "each loop acc 0.950216450216\n",
      "each loop rbf acc 0.965367965368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.43      0.50      0.46         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       0.86      1.00      0.92         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       1.00      0.83      0.91         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.25      0.17      0.20         6\n",
      "         28       0.86      1.00      0.92         6\n",
      "         29       1.00      0.50      0.67         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.67      1.00      0.80         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      0.83      0.91         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.57      0.67      0.62         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.75      1.00      0.86         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      0.67      0.80         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      0.83      0.91         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       0.86      1.00      0.92         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.96      0.96      0.96       462\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.62      0.83      0.71         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       1.00      1.00      1.00         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       1.00      1.00      1.00         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       1.00      0.50      0.67         6\n",
      "         28       1.00      0.83      0.91         6\n",
      "         29       0.60      0.50      0.55         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.57      0.67      0.62         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      1.00      1.00         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.86      1.00      0.92         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.67      0.67      0.67         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       0.67      0.67      0.67         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       0.86      1.00      0.92         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       1.00      1.00      1.00         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.97      0.97      0.97       462\n",
      "\n",
      "each loop acc 0.961038961039\n",
      "each loop rbf acc 0.969696969697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.50      0.67      0.57         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       0.57      0.67      0.62         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       0.60      0.50      0.55         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       1.00      0.17      0.29         6\n",
      "         28       0.75      1.00      0.86         6\n",
      "         29       1.00      0.50      0.67         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.67      1.00      0.80         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      0.83      0.91         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.56      0.83      0.67         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.57      0.67      0.62         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       0.60      0.50      0.55         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      0.67      0.80         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       0.86      1.00      0.92         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.96      0.95      0.95       462\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.57      0.67      0.62         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       0.80      0.67      0.73         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       0.71      0.83      0.77         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       1.00      0.33      0.50         6\n",
      "         28       1.00      1.00      1.00         6\n",
      "         29       0.75      0.50      0.60         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.62      0.83      0.71         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      0.83      0.91         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.67      1.00      0.80         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.40      0.33      0.36         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       0.43      0.50      0.46         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      1.00      1.00         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       0.86      1.00      0.92         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.96      0.95      0.95       462\n",
      "\n",
      "each loop acc 0.948051948052\n",
      "each loop rbf acc 0.954545454545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.50      0.50      0.50         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       0.86      1.00      0.92         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       0.67      1.00      0.80         6\n",
      "         24       1.00      0.83      0.91         6\n",
      "         25       1.00      0.67      0.80         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.25      0.17      0.20         6\n",
      "         28       0.75      1.00      0.86         6\n",
      "         29       0.67      0.67      0.67         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.67      0.67      0.67         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      1.00      1.00         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.75      1.00      0.86         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.75      1.00      0.86         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      0.67      0.80         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      0.67      0.80         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       1.00      1.00      1.00         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       0.75      1.00      0.86         6\n",
      "         70       1.00      0.50      0.67         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.96      0.95      0.95       462\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.80      0.67      0.73         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       1.00      1.00      1.00         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       0.67      1.00      0.80         6\n",
      "         24       1.00      1.00      1.00         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.60      0.50      0.55         6\n",
      "         28       1.00      0.67      0.80         6\n",
      "         29       0.57      0.67      0.62         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.60      0.50      0.55         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      1.00      1.00         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.75      1.00      0.86         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.75      1.00      0.86         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      0.67      0.80         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       0.75      1.00      0.86         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       1.00      1.00      1.00         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      0.50      0.67         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.97      0.96      0.96       462\n",
      "\n",
      "each loop acc 0.952380952381\n",
      "each loop rbf acc 0.963203463203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.40      0.33      0.36         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       1.00      1.00      1.00         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       1.00      1.00      1.00         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.33      0.17      0.22         6\n",
      "         28       0.67      0.67      0.67         6\n",
      "         29       0.50      0.67      0.57         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.50      0.33      0.40         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      0.67      0.80         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.60      1.00      0.75         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       0.75      1.00      0.86         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      0.67      0.80         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       0.67      0.67      0.67         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       0.75      1.00      0.86         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.95      0.95      0.95       462\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       0.86      1.00      0.92         6\n",
      "          8       0.45      0.83      0.59         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       1.00      1.00      1.00         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      0.83      0.91         6\n",
      "         24       1.00      1.00      1.00         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.50      0.17      0.25         6\n",
      "         28       1.00      1.00      1.00         6\n",
      "         29       0.50      0.83      0.62         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.50      0.17      0.25         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      0.67      0.80         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.80      0.67      0.73         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       1.00      0.83      0.91         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       0.86      1.00      0.92         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      1.00      1.00         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       0.75      1.00      0.86         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.96      0.96      0.96       462\n",
      "\n",
      "each loop acc 0.950216450216\n",
      "each loop rbf acc 0.961038961039\n",
      "f1  0.9492344668318694\n",
      "Accuracy: 0.9523809523809523\n",
      "f1  0.96148046376847\n",
      "Accuracy: 0.9627705627705627\n",
      "here\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAADqCAYAAAClduxYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5b80f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import lsanomaly\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn import utils  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "\n",
    "# import the CSV from http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "# this will return a pandas dataframe.\n",
    "data = pd.read_csv('C:/Users/S/Documents/PY/increased30featuresfile.csv', low_memory=False)\n",
    "'''data.loc[data['UUID'] == \"RVTNB1502866560357\", \"attack\"] = 1  \n",
    "data.loc[data['UUID'] != \"RVTNB1502866560357\", \"attack\"] = -1\n",
    "df_majority = data[data['attack']==-1]\n",
    "df_minority = data[data['attack']==1]\n",
    "from sklearn.utils import resample\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=830,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "#print(data['attack'].value_counts())'''\n",
    "\n",
    "#target=np.array(target)\n",
    "#target = pd.DataFrame(target,columns=['attack'])\n",
    "\n",
    "#data.drop([\"UUID\"], axis=1, inplace=True)\n",
    "categorical_columns=[\"UUID\",\"Language\",\"Hardware_Model\",\"SDK_Version\",\"Manufacture\",\"Screen_Size\",\"Time_Zone\",\"Country_Code\"]\n",
    "cate_data = data[categorical_columns]\n",
    "\n",
    "#for col in data.columns.values:\n",
    "#    print(col, data[col].unique())\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "def label_encode(cate_data, columns):\n",
    "    for col in columns:\n",
    "        le = LabelEncoder()\n",
    "        col_values_unique = list(cate_data[col].unique())\n",
    "        le_fitted = le.fit(col_values_unique)\n",
    " \n",
    "        col_values = list(cate_data[col].values)\n",
    "        le.classes_\n",
    "        col_values_transformed = le.transform(col_values)\n",
    "        cate_data[col] = col_values_transformed\n",
    " \n",
    "to_be_encoded_cols = cate_data.columns.values\n",
    "label_encode(cate_data, to_be_encoded_cols)\n",
    "display(cate_data.head())\n",
    "target=cate_data['UUID']\n",
    "target=np.array(target)\n",
    "#target = pd.DataFrame(target)\n",
    "#target=target1.values\n",
    "\n",
    "data.drop([\"UUID\",\"Language\",\"Hardware_Model\",\"SDK_Version\",\"Manufacture\",\"Screen_Size\",\"Time_Zone\",\"Country_Code\"], axis=1, inplace=True)\n",
    "data=pd.concat([data,cate_data], axis=1)\n",
    "data.drop([\"UUID\"], axis=1, inplace=True)\n",
    "#display(scaled_data.head())\n",
    "\n",
    "\n",
    "# check the shape for sanity checking.\n",
    "data.shape\n",
    "display(data.head())\n",
    "print(\"initial data info\",data.info())\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"data is\",data.shape)\n",
    "from skfeature.function.information_theoretical_based import LCSI\n",
    "from skfeature.function.information_theoretical_based import MRMR\n",
    "\n",
    "from skfeature.utility.entropy_estimators import *\n",
    "import scipy.io\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaled_data=data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaleddata= pd.DataFrame(scaled_data)\n",
    "scaled_data=np.array(scaled_data)\n",
    "\n",
    "print(scaled_data.shape)\n",
    "print(target.shape)\n",
    "#display(scaled_data.head())\n",
    "\n",
    "#display(target.head())\n",
    "#idx=MRMR.mrmr(scaled_data,target,n_selected_features=50)\n",
    "'''from sklearn import cross_validation\n",
    "ss = cross_validation.KFold(5, n_folds=5, shuffle=True)\n",
    "correct = 0\n",
    "print(\"scaled data details - \",scaled_data.info())\n",
    "print(\"target data details - \",target.info())\n",
    "for train, test in ss:\n",
    "    #print(scaled_data[train])\n",
    "    #print(target[train])\n",
    "        # obtain the index of each feature on the training set\n",
    "    idx,_,_ = MRMR.mrmr(scaled_data[train], target[train], n_selected_features=50)\n",
    "\n",
    "        # obtain the dataset on the selected features\n",
    "    features = scaled_data[:, idx[0:50]]\n",
    "print(features)    '''\n",
    "'''skb= SVC(kernel=\"linear\")\n",
    "rfe = RFE(estimator=skb, n_features_to_select=70)\n",
    "rfe=rfe.fit(scaleddata,target)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "skft = StratifiedKFold(n_splits=5,shuffle=True,random_state=36851234)\n",
    "for train, test in skft:\n",
    "    X_train,X_test=scaled_data.iloc[train],scaled_data.iloc[test]\n",
    "    Y_train,y_test=target.iloc[train],target.iloc[test]\n",
    "    model1 = svm.OneClassSVM(nu=nu, kernel='rbf', gamma=0.10000000000000001)  \n",
    "    model1.fit(X_train, Y_train)\n",
    "    scores = cross_val_score(model1,X_test,y_test, cv=5, scoring='accuracy')\n",
    "    print(scores)\n",
    "print(scores.mean())'''\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ss = cross_validation.KFold(5, n_folds=5, shuffle=True)\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5,random_state=36851234)\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=36851234)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "'''clf = svm.SVC(decision_function_shape='ovo',kernel='rbf')    # linear SVM\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=skf)\n",
    "grid.fit(scaled_data, target)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"% (grid.best_params_, grid.best_score_))'''\n",
    "plt.figure(figsize=(8, 8))\n",
    "accuracy = plt.subplot(211)\n",
    "box=plt.subplot(211)\n",
    "from sklearn.svm import LinearSVC\n",
    "clf=SVC(kernel='linear')\n",
    "#clf=LinearSVC()\n",
    "rbf=SVC(decision_function_shape='ovo',gamma=0.001,C=10000.0)\n",
    "correct = 0\n",
    "fscoreTotal =0\n",
    "rbf_correct = 0\n",
    "rbf_fscoreTotal =0\n",
    "results=[]\n",
    "for train, test in skf.split(scaled_data,target):\n",
    "        # obtain the index of each feature on the training set\n",
    "    idx,_,_ = MRMR.mrmr(scaled_data[train], target[train], n_selected_features=36)\n",
    "\n",
    "        # obtain the dataset on the selected features\n",
    "    features = scaled_data[:, idx[0:36]]\n",
    "        #print(target[train])\n",
    "        # train a classification model with the selected features on the training dataset\n",
    "    clf.fit(features[train], target[train])\n",
    "    #clf1.fit(scaled_data[train],target[train])\n",
    "    rbf.fit(features[train], target[train])\n",
    "        # predict the class labels of test data\n",
    "    y_predict = clf.predict(features[test])\n",
    "    #y_predict = clf1.predict(scaled_data[test])\n",
    "    rbf_y_predict = rbf.predict(features[test])\n",
    "    print(\"metrics\")\n",
    "        # obtain the classification accuracy on the test data\n",
    "    acc = accuracy_score(target[test], y_predict)\n",
    "    rbf_acc = accuracy_score(target[test], rbf_y_predict)\n",
    "    correct = correct + acc\n",
    "    rbf_correct = rbf_correct + rbf_acc\n",
    "    fscore=f1_score(target[test], y_predict,average='weighted')\n",
    "    rbf_fscore=f1_score(target[test], rbf_y_predict,average='weighted')\n",
    "    fscoreTotal=fscoreTotal+fscore\n",
    "    rbf_fscoreTotal=rbf_fscoreTotal+rbf_fscore\n",
    "        #print(\"fsc \",f1_score(target[test], y_predict,average='weighted'))\n",
    "        #print(\"conf mat \",confusion_matrix(target[test],y_predict))\n",
    "        #print(\"ACCURACY: \", (accuracy_score(target[test], y_predict)))\n",
    "    report = classification_report(target[test], y_predict)\n",
    "    print(report)\n",
    "    rbreport = classification_report(target[test], rbf_y_predict)\n",
    "    print(rbreport)\n",
    "    print(\"each loop acc\",acc)\n",
    "    print(\"each loop rbf acc\",rbf_acc)\n",
    "score=float(correct)/5\n",
    "rbfscore=float(rbf_correct)/5\n",
    "results.append(score)\n",
    "results.append(rbfscore)\n",
    "print(\"f1 \",float(fscoreTotal)/5)\n",
    "    # output the average classification accuracy over all 10 folds\n",
    "print(\"Accuracy:\", float(correct)/5)\n",
    "print(\"f1 \",float(rbf_fscoreTotal)/5)\n",
    "    # output the average classification accuracy over all 10 folds\n",
    "print(\"Accuracy:\", float(rbf_correct)/5)\n",
    "\n",
    "accuracy.plot([scaled_data.shape[1], scaled_data.shape[0]],\n",
    "              [score, score], label=\"linear svm\")\n",
    "accuracy.plot([scaled_data.shape[1], scaled_data.shape[0]],\n",
    "              [rbfscore, rbfscore], label=\"rbf svm with grid search C=10000 and gamma=0.001\")\n",
    "accuracy.set_title(\"Classification accuracy\")\n",
    "accuracy.set_xlim(scaled_data.shape[1], scaled_data.shape[0])\n",
    "accuracy.set_xticks(())\n",
    "accuracy.set_ylim(0.90, 1)\n",
    "accuracy.set_ylabel(\"Classification accuracy\")\n",
    "accuracy.legend(loc='best')\n",
    "##svc=SelectKBest(mutual_info_classif, k=50).fit_transform(data,target)\n",
    "#svc = SVC(kernel=\"linear\")\n",
    "#rfe = RFE(estimator=svc, n_features_to_select=10)\n",
    "#rfe.fit(data, target)\n",
    "print(\"here\")\n",
    "box.boxplot(results)\n",
    "box.set_title(\"Classification accuracy\")\n",
    "box.set_xlim(scaled_data.shape[1], scaled_data.shape[0])\n",
    "box.set_xticks(())\n",
    "box.set_ylim(0.90, 1)\n",
    "box.set_ylabel(\"Classification accuracy\")\n",
    "box.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UUID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hardware_Model</th>\n",
       "      <th>SDK_Version</th>\n",
       "      <th>Manufacture</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UUID  Language  Hardware_Model  SDK_Version  Manufacture  Screen_Size  \\\n",
       "0    48         0              40            3           18           23   \n",
       "1    48         0              40            3           18           23   \n",
       "2    48         0              40            3           18           23   \n",
       "3    48         0              40            3           18           23   \n",
       "4    48         0              40            3           18           23   \n",
       "\n",
       "   Time_Zone  Country_Code  \n",
       "0          7             1  \n",
       "1          7             1  \n",
       "2          7             1  \n",
       "3          7             1  \n",
       "4          7             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_of_CPU_Cores</th>\n",
       "      <th>pLN1</th>\n",
       "      <th>p.2</th>\n",
       "      <th>pLN3</th>\n",
       "      <th>pt4</th>\n",
       "      <th>pi5</th>\n",
       "      <th>pe6</th>\n",
       "      <th>pLN7</th>\n",
       "      <th>p58</th>\n",
       "      <th>pLN9</th>\n",
       "      <th>...</th>\n",
       "      <th>avdu2</th>\n",
       "      <th>avgp</th>\n",
       "      <th>avga</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hardware_Model</th>\n",
       "      <th>SDK_Version</th>\n",
       "      <th>Manufacture</th>\n",
       "      <th>Screen_Size</th>\n",
       "      <th>Time_Zone</th>\n",
       "      <th>Country_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>575.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>466.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num_of_CPU_Cores  pLN1  p.2  pLN3  pt4  pi5  pe6  pLN7  p58  pLN9  \\\n",
       "0               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "1               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "2               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "3               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "4               8.0   1.0  1.0   1.0  1.0  1.0  1.0   1.0  1.0   1.0   \n",
       "\n",
       "       ...            avdu2  avgp      avga  Language  Hardware_Model  \\\n",
       "0      ...        88.200000   1.0  0.004412         0              40   \n",
       "1      ...        95.400000   1.0  0.004167         0              40   \n",
       "2      ...       575.333333   1.0  0.008333         0              40   \n",
       "3      ...       466.400000   1.0  0.008211         0              40   \n",
       "4      ...       121.800000   1.0  0.009804         0              40   \n",
       "\n",
       "   SDK_Version  Manufacture  Screen_Size  Time_Zone  Country_Code  \n",
       "0            3           18           23          7             1  \n",
       "1            3           18           23          7             1  \n",
       "2            3           18           23          7             1  \n",
       "3            3           18           23          7             1  \n",
       "4            3           18           23          7             1  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2310 entries, 0 to 2309\n",
      "Columns: 155 entries, Num_of_CPU_Cores to Country_Code\n",
      "dtypes: float64(148), int64(7)\n",
      "memory usage: 2.7 MB\n",
      "initial data info None\n",
      "data is (2310, 155)\n",
      "(2310, 155)\n",
      "(2310,)\n",
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.80      0.67      0.73         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       1.00      1.00      1.00         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       1.00      1.00      1.00         6\n",
      "         25       1.00      0.83      0.91         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.83      0.83      0.83         6\n",
      "         28       1.00      1.00      1.00         6\n",
      "         29       1.00      1.00      1.00         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       1.00      1.00      1.00         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      1.00      1.00         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       0.86      1.00      0.92         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.86      1.00      0.92         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       1.00      1.00      1.00         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      1.00      1.00         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      1.00      1.00         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       1.00      1.00      1.00         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.99      0.99      0.99       462\n",
      "\n",
      "each loop acc 0.991341991342\n",
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.86      1.00      0.92         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       0.86      1.00      0.92         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       0.86      1.00      0.92         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       1.00      1.00      1.00         6\n",
      "         28       1.00      1.00      1.00         6\n",
      "         29       1.00      0.83      0.91         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.86      1.00      0.92         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       0.86      1.00      0.92         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       1.00      1.00      1.00         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       1.00      0.83      0.91         6\n",
      "         46       1.00      0.67      0.80         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       0.86      1.00      0.92         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      0.83      0.91         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      1.00      1.00         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       1.00      0.83      0.91         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.99      0.99      0.99       462\n",
      "\n",
      "each loop acc 0.987012987013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       0.83      0.83      0.83         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       1.00      0.83      0.91         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       1.00      0.83      0.91         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.83      0.83      0.83         6\n",
      "         28       1.00      1.00      1.00         6\n",
      "         29       0.86      1.00      0.92         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       1.00      0.83      0.91         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      1.00      1.00         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       1.00      1.00      1.00         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       1.00      1.00      1.00         6\n",
      "         46       0.75      1.00      0.86         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      1.00      1.00         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      1.00      1.00         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       1.00      1.00      1.00         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.99      0.99      0.99       462\n",
      "\n",
      "each loop acc 0.989177489177\n",
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         6\n",
      "          9       0.86      1.00      0.92         6\n",
      "         10       1.00      1.00      1.00         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       1.00      1.00      1.00         6\n",
      "         25       0.86      1.00      0.92         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       1.00      0.83      0.91         6\n",
      "         28       1.00      1.00      1.00         6\n",
      "         29       1.00      0.83      0.91         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       0.86      1.00      0.92         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      1.00      1.00         6\n",
      "         35       1.00      0.83      0.91         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      0.83      0.91         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       0.86      1.00      0.92         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       1.00      1.00      1.00         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       1.00      1.00      1.00         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      1.00      1.00         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      1.00      1.00         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       1.00      1.00      1.00         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.99      0.99      0.99       462\n",
      "\n",
      "each loop acc 0.991341991342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.83      0.91         6\n",
      "          1       1.00      1.00      1.00         6\n",
      "          2       1.00      1.00      1.00         6\n",
      "          3       1.00      1.00      1.00         6\n",
      "          4       1.00      1.00      1.00         6\n",
      "          5       1.00      1.00      1.00         6\n",
      "          6       1.00      1.00      1.00         6\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      0.83      0.91         6\n",
      "          9       1.00      1.00      1.00         6\n",
      "         10       1.00      1.00      1.00         6\n",
      "         11       1.00      1.00      1.00         6\n",
      "         12       1.00      1.00      1.00         6\n",
      "         13       1.00      1.00      1.00         6\n",
      "         14       1.00      1.00      1.00         6\n",
      "         15       1.00      1.00      1.00         6\n",
      "         16       1.00      1.00      1.00         6\n",
      "         17       1.00      1.00      1.00         6\n",
      "         18       1.00      1.00      1.00         6\n",
      "         19       1.00      1.00      1.00         6\n",
      "         20       1.00      1.00      1.00         6\n",
      "         21       1.00      1.00      1.00         6\n",
      "         22       1.00      1.00      1.00         6\n",
      "         23       1.00      1.00      1.00         6\n",
      "         24       1.00      1.00      1.00         6\n",
      "         25       1.00      1.00      1.00         6\n",
      "         26       1.00      1.00      1.00         6\n",
      "         27       0.86      1.00      0.92         6\n",
      "         28       1.00      1.00      1.00         6\n",
      "         29       0.86      1.00      0.92         6\n",
      "         30       1.00      1.00      1.00         6\n",
      "         31       1.00      0.83      0.91         6\n",
      "         32       1.00      1.00      1.00         6\n",
      "         33       1.00      1.00      1.00         6\n",
      "         34       1.00      0.83      0.91         6\n",
      "         35       1.00      1.00      1.00         6\n",
      "         36       1.00      1.00      1.00         6\n",
      "         37       1.00      1.00      1.00         6\n",
      "         38       1.00      1.00      1.00         6\n",
      "         39       1.00      1.00      1.00         6\n",
      "         40       1.00      1.00      1.00         6\n",
      "         41       1.00      1.00      1.00         6\n",
      "         42       1.00      1.00      1.00         6\n",
      "         43       0.86      1.00      0.92         6\n",
      "         44       1.00      1.00      1.00         6\n",
      "         45       1.00      1.00      1.00         6\n",
      "         46       1.00      1.00      1.00         6\n",
      "         47       1.00      1.00      1.00         6\n",
      "         48       1.00      1.00      1.00         6\n",
      "         49       1.00      1.00      1.00         6\n",
      "         50       1.00      1.00      1.00         6\n",
      "         51       1.00      1.00      1.00         6\n",
      "         52       1.00      1.00      1.00         6\n",
      "         53       1.00      1.00      1.00         6\n",
      "         54       1.00      1.00      1.00         6\n",
      "         55       1.00      1.00      1.00         6\n",
      "         56       1.00      1.00      1.00         6\n",
      "         57       1.00      1.00      1.00         6\n",
      "         58       1.00      1.00      1.00         6\n",
      "         59       1.00      1.00      1.00         6\n",
      "         60       1.00      1.00      1.00         6\n",
      "         61       1.00      1.00      1.00         6\n",
      "         62       1.00      1.00      1.00         6\n",
      "         63       1.00      1.00      1.00         6\n",
      "         64       1.00      1.00      1.00         6\n",
      "         65       1.00      1.00      1.00         6\n",
      "         66       1.00      1.00      1.00         6\n",
      "         67       0.86      1.00      0.92         6\n",
      "         68       1.00      1.00      1.00         6\n",
      "         69       1.00      1.00      1.00         6\n",
      "         70       1.00      1.00      1.00         6\n",
      "         71       1.00      1.00      1.00         6\n",
      "         72       1.00      1.00      1.00         6\n",
      "         73       1.00      1.00      1.00         6\n",
      "         74       1.00      1.00      1.00         6\n",
      "         75       1.00      1.00      1.00         6\n",
      "         76       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.99      0.99      0.99       462\n",
      "\n",
      "each loop acc 0.991341991342\n",
      "random f1  0.9899277346030594\n",
      "random Accuracy: 0.9900432900432901\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import lsanomaly\n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn import utils  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "\n",
    "\n",
    "# import the CSV from http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "# this will return a pandas dataframe.\n",
    "data = pd.read_csv('C:/Users/S/Documents/PY/increased30featuresfile.csv', low_memory=False)\n",
    "'''data.loc[data['UUID'] == \"RVTNB1502866560357\", \"attack\"] = 1  \n",
    "data.loc[data['UUID'] != \"RVTNB1502866560357\", \"attack\"] = -1\n",
    "df_majority = data[data['attack']==-1]\n",
    "df_minority = data[data['attack']==1]\n",
    "from sklearn.utils import resample\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=830,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "#print(data['attack'].value_counts())'''\n",
    "\n",
    "#target=np.array(target)\n",
    "#target = pd.DataFrame(target,columns=['attack'])\n",
    "\n",
    "#data.drop([\"UUID\"], axis=1, inplace=True)\n",
    "categorical_columns=[\"UUID\",\"Language\",\"Hardware_Model\",\"SDK_Version\",\"Manufacture\",\"Screen_Size\",\"Time_Zone\",\"Country_Code\"]\n",
    "cate_data = data[categorical_columns]\n",
    "\n",
    "#for col in data.columns.values:\n",
    "#    print(col, data[col].unique())\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "def label_encode(cate_data, columns):\n",
    "    for col in columns:\n",
    "        le = LabelEncoder()\n",
    "        col_values_unique = list(cate_data[col].unique())\n",
    "        le_fitted = le.fit(col_values_unique)\n",
    " \n",
    "        col_values = list(cate_data[col].values)\n",
    "        le.classes_\n",
    "        col_values_transformed = le.transform(col_values)\n",
    "        cate_data[col] = col_values_transformed\n",
    " \n",
    "to_be_encoded_cols = cate_data.columns.values\n",
    "label_encode(cate_data, to_be_encoded_cols)\n",
    "display(cate_data.head())\n",
    "target=cate_data['UUID']\n",
    "target=np.array(target)\n",
    "#target = pd.DataFrame(target)\n",
    "#target=target1.values\n",
    "\n",
    "data.drop([\"UUID\",\"Language\",\"Hardware_Model\",\"SDK_Version\",\"Manufacture\",\"Screen_Size\",\"Time_Zone\",\"Country_Code\"], axis=1, inplace=True)\n",
    "data=pd.concat([data,cate_data], axis=1)\n",
    "data.drop([\"UUID\"], axis=1, inplace=True)\n",
    "#display(scaled_data.head())\n",
    "\n",
    "\n",
    "# check the shape for sanity checking.\n",
    "data.shape\n",
    "display(data.head())\n",
    "print(\"initial data info\",data.info())\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"data is\",data.shape)\n",
    "from skfeature.function.information_theoretical_based import LCSI\n",
    "from skfeature.function.information_theoretical_based import MRMR\n",
    "\n",
    "from skfeature.utility.entropy_estimators import *\n",
    "import scipy.io\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaled_data=data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaleddata= pd.DataFrame(scaled_data)\n",
    "scaled_data=np.array(scaled_data)\n",
    "\n",
    "print(scaled_data.shape)\n",
    "print(target.shape)\n",
    "#display(scaled_data.head())\n",
    "\n",
    "#display(target.head())\n",
    "#idx=MRMR.mrmr(scaled_data,target,n_selected_features=50)\n",
    "'''from sklearn import cross_validation\n",
    "ss = cross_validation.KFold(5, n_folds=5, shuffle=True)\n",
    "correct = 0\n",
    "print(\"scaled data details - \",scaled_data.info())\n",
    "print(\"target data details - \",target.info())\n",
    "for train, test in ss:\n",
    "    #print(scaled_data[train])\n",
    "    #print(target[train])\n",
    "        # obtain the index of each feature on the training set\n",
    "    idx,_,_ = MRMR.mrmr(scaled_data[train], target[train], n_selected_features=50)\n",
    "\n",
    "        # obtain the dataset on the selected features\n",
    "    features = scaled_data[:, idx[0:50]]\n",
    "print(features)    '''\n",
    "'''skb= SVC(kernel=\"linear\")\n",
    "rfe = RFE(estimator=skb, n_features_to_select=70)\n",
    "rfe=rfe.fit(scaleddata,target)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "skft = StratifiedKFold(n_splits=5,shuffle=True,random_state=36851234)\n",
    "for train, test in skft:\n",
    "    X_train,X_test=scaled_data.iloc[train],scaled_data.iloc[test]\n",
    "    Y_train,y_test=target.iloc[train],target.iloc[test]\n",
    "    model1 = svm.OneClassSVM(nu=nu, kernel='rbf', gamma=0.10000000000000001)  \n",
    "    model1.fit(X_train, Y_train)\n",
    "    scores = cross_val_score(model1,X_test,y_test, cv=5, scoring='accuracy')\n",
    "    print(scores)\n",
    "print(scores.mean())'''\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "ss = cross_validation.KFold(5, n_folds=5, shuffle=True)\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5,random_state=36851234)\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=36851234)\n",
    "''''from sklearn.model_selection import GridSearchCV\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "clf = svm.SVC(decision_function_shape='ovo',kernel='rbf')    # linear SVM\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=skf)\n",
    "grid.fit(scaled_data, target)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"% (grid.best_params_, grid.best_score_))'''\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "clf=RandomForestClassifier(n_estimators=5,class_weight='balanced')\n",
    "\n",
    "\n",
    "correct = 0\n",
    "fscoreTotal =0\n",
    "\n",
    "results=[]\n",
    "for train, test in skf.split(scaled_data,target):\n",
    "        # obtain the index of each feature on the training set\n",
    "    idx,_,_ = MRMR.mrmr(scaled_data[train], target[train], n_selected_features=36)\n",
    "\n",
    "        # obtain the dataset on the selected features\n",
    "    features = scaled_data[:, idx[0:36]]\n",
    "    \n",
    "        # train a classification model with the selected features on the training dataset\n",
    "    clf.fit(features[train], target[train])\n",
    "    #clf1.fit(scaled_data[train],target[train])\n",
    "    \n",
    "        # predict the class labels of test data\n",
    "    y_predict = clf.predict(features[test])\n",
    "    #y_predict = clf1.predict(scaled_data[test])\n",
    "    \n",
    "    print(\"metrics\")\n",
    "        # obtain the classification accuracy on the test data\n",
    "    acc = accuracy_score(target[test], y_predict)\n",
    "    \n",
    "    correct = correct + acc\n",
    "    \n",
    "    fscore=f1_score(target[test], y_predict,average='weighted')\n",
    "    \n",
    "    fscoreTotal=fscoreTotal+fscore\n",
    "    \n",
    "        #print(\"fsc \",f1_score(target[test], y_predict,average='weighted'))\n",
    "        #print(\"conf mat \",confusion_matrix(target[test],y_predict))\n",
    "        #print(\"ACCURACY: \", (accuracy_score(target[test], y_predict)))\n",
    "    report = classification_report(target[test], y_predict)\n",
    "    print(report)\n",
    "    \n",
    "    print(\"each loop acc\",acc)\n",
    "   \n",
    "score=float(correct)/5\n",
    "\n",
    "results.append(score)\n",
    "\n",
    "print(\"random f1 \",float(fscoreTotal)/5)\n",
    "    # output the average classification accuracy over all 10 folds\n",
    "print(\"random Accuracy:\", float(correct)/5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
